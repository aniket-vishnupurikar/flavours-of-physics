{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will train the best model obtained from experimentation, save that model, load it from memory. Then we will define a function that will give us the result for a given data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "train_df = pd.read_csv(\"training.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "agree_df = pd.read_csv(\"check_agreement.csv\")\n",
    "corr_df = pd.read_csv(\"check_correlation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agrrement test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreement test as mentioned in kaggle resources#\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def __roc_curve_splitted(data_zero, data_one, sample_weights_zero, sample_weights_one):\n",
    "    \"\"\"\n",
    "    Compute roc curve\n",
    "\n",
    "    :param data_zero: 0-labeled data\n",
    "    :param data_one:  1-labeled data\n",
    "    :param sample_weights_zero: weights for 0-labeled data\n",
    "    :param sample_weights_one:  weights for 1-labeled data\n",
    "    :return: roc curve\n",
    "    \"\"\"\n",
    "    labels = [0] * len(data_zero) + [1] * len(data_one)\n",
    "    weights = np.concatenate([sample_weights_zero, sample_weights_one])\n",
    "    data_all = np.concatenate([data_zero, data_one])\n",
    "    fpr, tpr, _ = roc_curve(labels, data_all, sample_weight=weights)\n",
    "    return fpr, tpr\n",
    "\n",
    "def compute_ks(data_prediction, mc_prediction, weights_data, weights_mc):\n",
    "    \"\"\"\n",
    "    Compute Kolmogorov-Smirnov (ks) distance between real data predictions cdf and Monte Carlo one.\n",
    "\n",
    "    :param data_prediction: array-like, real data predictions\n",
    "    :param mc_prediction: array-like, Monte Carlo data predictions\n",
    "    :param weights_data: array-like, real data weights\n",
    "    :param weights_mc: array-like, Monte Carlo weights\n",
    "    :return: ks value\n",
    "    \"\"\"\n",
    "    assert len(data_prediction) == len(weights_data), 'Data length and weight one must be the same'\n",
    "    assert len(mc_prediction) == len(weights_mc), 'Data length and weight one must be the same'\n",
    "\n",
    "    data_prediction, mc_prediction = np.array(data_prediction), np.array(mc_prediction)\n",
    "    weights_data, weights_mc = np.array(weights_data), np.array(weights_mc)\n",
    "\n",
    "    assert np.all(data_prediction >= 0.) and np.all(data_prediction <= 1.), 'Data predictions are out of range [0, 1]'\n",
    "    assert np.all(mc_prediction >= 0.) and np.all(mc_prediction <= 1.), 'MC predictions are out of range [0, 1]'\n",
    "\n",
    "    weights_data /= np.sum(weights_data)\n",
    "    weights_mc /= np.sum(weights_mc)\n",
    "\n",
    "    fpr, tpr = __roc_curve_splitted(data_prediction, mc_prediction, weights_data, weights_mc)\n",
    "\n",
    "    Dnm = np.max(np.abs(fpr - tpr))\n",
    "    return Dnm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation test as mentioned in kaggle resources\n",
    "\n",
    "def __rolling_window(data, window_size):\n",
    "    \"\"\"\n",
    "    Rolling window: take window with definite size through the array\n",
    "\n",
    "    :param data: array-like\n",
    "    :param window_size: size\n",
    "    :return: the sequence of windows\n",
    "\n",
    "    Example: data = array(1, 2, 3, 4, 5, 6), window_size = 4\n",
    "        Then this function return array(array(1, 2, 3, 4), array(2, 3, 4, 5), array(3, 4, 5, 6))\n",
    "    \"\"\"\n",
    "    shape = data.shape[:-1] + (data.shape[-1] - window_size + 1, window_size)\n",
    "    strides = data.strides + (data.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "def __cvm(subindices, total_events):\n",
    "    \"\"\"\n",
    "    Compute Cramer-von Mises metric.\n",
    "    Compared two distributions, where first is subset of second one.\n",
    "    Assuming that second is ordered by ascending\n",
    "\n",
    "    :param subindices: indices of events which will be associated with the first distribution\n",
    "    :param total_events: count of events in the second distribution\n",
    "    :return: cvm metric\n",
    "    \"\"\"\n",
    "    target_distribution = np.arange(1, total_events + 1, dtype='float') / total_events\n",
    "    subarray_distribution = np.cumsum(np.bincount(subindices, minlength=total_events), dtype='float')\n",
    "    subarray_distribution /= 1.0 * subarray_distribution[-1]\n",
    "    return np.mean((target_distribution - subarray_distribution) ** 2)\n",
    "\n",
    "def compute_cvm(predictions, masses, n_neighbours=200, step=50):\n",
    "    \"\"\"\n",
    "    Computing Cramer-von Mises (cvm) metric on background events: take average of cvms calculated for each mass bin.\n",
    "    In each mass bin global prediction's cdf is compared to prediction's cdf in mass bin.\n",
    "\n",
    "    :param predictions: array-like, predictions\n",
    "    :param masses: array-like, in case of Kaggle tau23mu this is reconstructed mass\n",
    "    :param n_neighbours: count of neighbours for event to define mass bin\n",
    "    :param step: step through sorted mass-array to define next center of bin\n",
    "    :return: average cvm value\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    masses = np.array(masses)\n",
    "    assert len(predictions) == len(masses)\n",
    "\n",
    "    # First, reorder by masses\n",
    "    predictions = predictions[np.argsort(masses)]\n",
    "\n",
    "    # Second, replace probabilities with order of probability among other events\n",
    "    predictions = np.argsort(np.argsort(predictions, kind='mergesort'), kind='mergesort')\n",
    "\n",
    "    # Now, each window forms a group, and we can compute contribution of each group to CvM\n",
    "    cvms = []\n",
    "    for window in __rolling_window(predictions, window_size=n_neighbours)[::step]:\n",
    "        cvms.append(__cvm(subindices=window, total_events=len(predictions)))\n",
    "    return np.mean(cvms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "def new_feats(df):\n",
    "    df2 = df.copy()\n",
    "    df2['isolation_abc'] = df['isolationa'] + df['isolationb'] + df['isolationc']\n",
    "    df2['isolation_def'] = df['isolationd'] + df['isolatione'] + df['isolationf']\n",
    "    df2['p_IP'] = df['p0_IP']+df['p1_IP']+df['p2_IP']\n",
    "    df2['p_p']  = df['p0_p']+df['p1_p']+df['p2_p']\n",
    "    df2['IP_pp'] = df['IP_p0p2'] + df['IP_p1p2']\n",
    "    df2['p_IPSig'] = df['p0_IPSig'] + df['p1_IPSig'] + df['p2_IPSig']\n",
    "    #new feature using 'FlightDu=istance' and LifeTime(from literature)\n",
    "    df2['FD_LT']=df['FlightDistance']/df['LifeTime']\n",
    "    #new feature using 'FlightDistance', 'po_p', 'p1_p', 'p2_p'(from literature)\n",
    "    df2['FD_p0p1p2_p']=df['FlightDistance']/(df['p0_p']+df['p1_p']+df['p2_p'])\n",
    "    #new feature using 'LifeTime', 'p0_IP', 'p1_IP', 'p2_IP'(from literature)\n",
    "    df2['NEW5_lt']=df['LifeTime']*(df['p0_IP']+df['p1_IP']+df['p2_IP'])/3\n",
    "    #new feature using 'p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof'(taking max value among 3 features for each row)\n",
    "    df2['Chi2Dof_MAX'] = df.loc[:, ['p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof']].max(axis=1)\n",
    "    # features from kaggle discussion forum\n",
    "    df2['flight_dist_sig2'] = (df['FlightDistance']/df['FlightDistanceError'])**2\n",
    "    df2['flight_dist_sig'] = df['FlightDistance']/df['FlightDistanceError']\n",
    "    df2['NEW_IP_dira'] = df['IP']*df['dira']\n",
    "    df2['p0p2_ip_ratio']=df['IP']/df['IP_p0p2']\n",
    "    df2['p1p2_ip_ratio']=df['IP']/df['IP_p1p2']\n",
    "    df2['DCA_MAX'] = df.loc[:, ['DOCAone', 'DOCAtwo', 'DOCAthree']].max(axis=1)\n",
    "    df2['iso_bdt_min'] = df.loc[:, ['p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT']].min(axis=1)\n",
    "    df2['iso_min'] = df.loc[:, ['isolationa', 'isolationb', 'isolationc','isolationd', 'isolatione', 'isolationf']].min(axis=1)\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding engineered features to training and test datasets\n",
    "train_df_1 = new_feats(train_df)\n",
    "test_df_1 = new_feats(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idenifying some features to remove which have been used to engineer new features and which have been observed to be of \n",
    "#low importance in EDA\n",
    "remove = ['id', 'min_ANNmuon', 'production', 'mass', 'signal','SPDhits','CDF1', 'CDF2', 'CDF3','isolationb', 'isolationc',\n",
    "          'p0_pt', 'p1_pt', 'p2_pt','p0_p', 'p1_p', 'p2_p', 'p0_eta', 'p1_eta', 'p2_eta','isolationa', 'isolationb',\n",
    "          'isolationc', 'isolationd', 'isolatione', 'isolationf','p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT','p0_IP', 'p1_IP',\n",
    "          'p2_IP','IP_p0p2', 'IP_p1p2','p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof','p0_IPSig', 'p1_IPSig',\n",
    "          'p2_IPSig','DOCAone', 'DOCAtwo', 'DOCAthree']\n",
    "# making a list of features to be used to train the model and make predictions\n",
    "features = list(f for f in train_df_1.columns if f not in remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UGradientBoostingClassifier(learning_rate=0.15,\n",
       "                            loss=BinFlatnessLossFunction(allow_wrong_signs=True,\n",
       "                                                         fl_coefficient=15,\n",
       "                                                         n_bins=15, power=2,\n",
       "                                                         uniform_features=['mass'],\n",
       "                                                         uniform_label=array([0])),\n",
       "                            max_depth=6, max_features=None, max_leaf_nodes=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            n_estimators=900,\n",
       "                            random_state=RandomState(MT19937) at 0x259BE7B3740,\n",
       "                            splitter...\n",
       "                            train_features=['LifeTime', 'dira',\n",
       "                                            'FlightDistance',\n",
       "                                            'FlightDistanceError', 'IP',\n",
       "                                            'IPSig', 'VertexChi2', 'pt', 'iso',\n",
       "                                            'ISO_SumBDT', 'isolation_abc',\n",
       "                                            'isolation_def', 'p_IP', 'p_p',\n",
       "                                            'IP_pp', 'p_IPSig', 'FD_LT',\n",
       "                                            'FD_p0p1p2_p', 'NEW5_lt',\n",
       "                                            'Chi2Dof_MAX', 'flight_dist_sig2',\n",
       "                                            'flight_dist_sig', 'NEW_IP_dira',\n",
       "                                            'p0p2_ip_ratio', 'p1p2_ip_ratio',\n",
       "                                            'DCA_MAX', 'iso_bdt_min',\n",
       "                                            'iso_min'],\n",
       "                            update_tree=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the actual model\n",
    "from hep_ml.gradientboosting import UGradientBoostingClassifier\n",
    "from hep_ml.losses import BinFlatnessLossFunction\n",
    "loss = BinFlatnessLossFunction(['mass'], n_bins=15, uniform_label=0 , fl_coefficient=15, power=2)\n",
    "model = UGradientBoostingClassifier(loss=loss, n_estimators=900,\n",
    "                                 max_depth=6,\n",
    "                                 learning_rate=0.15,\n",
    "                                 train_features=features,\n",
    "                                 subsample=0.7)\n",
    "model.fit(train_df_1[features + ['mass']], train_df_1['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model to the memory\n",
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model from memory\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS metric 0.0777479828637741\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# conducting agreement check test\n",
    "check_agreement = pd.read_csv(\"check_agreement.csv\")\n",
    "check_agreement = new_feats(check_agreement)\n",
    "\n",
    "#check_agreement = pandas.read_csv(folder + 'check_agreement.csv', index_col='id')\n",
    "agreement_probs = loaded_model.predict_proba(check_agreement[features])[:, 1]\n",
    "\n",
    "ks = compute_ks(\n",
    "    agreement_probs[check_agreement['signal'].values == 0],\n",
    "    agreement_probs[check_agreement['signal'].values == 1],\n",
    "    check_agreement[check_agreement['signal'] == 0]['weight'].values,\n",
    "    check_agreement[check_agreement['signal'] == 1]['weight'].values)\n",
    "#print 'KS metric', ks, ks < 0.09\n",
    "print(\"KS metric {}\".format(ks))\n",
    "print(ks < 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CvM metric 0.0018304056413095619\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# conducting the correlation test\n",
    "#check_correlation = pandas.read_csv(folder + 'check_correlation.csv', index_col='id')\n",
    "check_correlation = pd.read_csv(\"check_correlation.csv\", index_col = \"id\")\n",
    "check_correlation = new_feats(check_correlation)\n",
    "correlation_probs = loaded_model.predict_proba(check_correlation[features])[:, 1]\n",
    "cvm = compute_cvm(correlation_probs, check_correlation['mass'])\n",
    "#print 'CvM metric', cvm, cvm < 0.002\n",
    "print(\"CvM metric {}\".format(cvm))\n",
    "print(cvm < 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making submission file with test dataset to be submitted on kaggle\n",
    "test_probs = loaded_model.predict_proba(test_df_1[features])[:,1]\n",
    "result = pd.DataFrame({\"id\": test_df[\"id\"], \"prediction\": test_probs})\n",
    "result.to_csv(\"final_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function which when given a a data point as a list returns the result for the same \n",
    "def compute(x):\n",
    "    \"\"\"given a data point, x, as a list of values this function returns the label for that data point\"\"\"\n",
    "    df = pd.DataFrame(data = np.array(x).reshape(1, len(x)), columns = list(test_df.columns))\n",
    "    df_1 = new_feats(df)\n",
    "    output = loaded_model.predict(df_1[features])[0]\n",
    "    if output == 0:\n",
    "        print(\"the given point belongs to class {} i.e. it is a background event\".format(output))\n",
    "    elif output == 1:\n",
    "        print(\"the given point belongs to class {} i.e. it is a signal event\".format(output))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the function with some test point\n",
    "test_1 = list(test_df.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the given point belongs to class 0 i.e. it is a background event\n"
     ]
    }
   ],
   "source": [
    "output_1 = compute(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = list(test_df.iloc[222].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the given point belongs to class 0 i.e. it is a background event\n"
     ]
    }
   ],
   "source": [
    "output_2 = compute(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the given point belongs to class 1 i.e. it is a signal event\n"
     ]
    }
   ],
   "source": [
    "test_3 = list(test_df.iloc[111].values)\n",
    "output_3 = compute(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
